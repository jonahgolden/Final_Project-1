{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kylefawkes\n"
     ]
    }
   ],
   "source": [
    "%cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kylefawkes/Desktop\n"
     ]
    }
   ],
   "source": [
    "%cd Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B2_mosquito_data.csv.txt\r\n",
      "\u001b[34mCPS_assignments\u001b[m\u001b[m/\r\n",
      "\u001b[34mFinal_Project-1\u001b[m\u001b[m/\r\n",
      "\u001b[34mFinal_Project-2\u001b[m\u001b[m/\r\n",
      "\u001b[34mInflammation\u001b[m\u001b[m/\r\n",
      "\u001b[34mPython_thoughts\u001b[m\u001b[m/\r\n",
      "Quick_and_Dirty_R.pdf\r\n",
      "Screen Shot 2014-10-07 at 11.12.28 PM.png\r\n",
      "Screen Shot 2015-10-27 at 9.36.09 PM.png\r\n",
      "WirelessDiagnostics-C1MN20C3DTY3-20150411101217.tar.gz\r\n",
      "\u001b[34mclass_notes\u001b[m\u001b[m/\r\n",
      "\u001b[34mcode_review\u001b[m\u001b[m/\r\n",
      "decays.csv.txt\r\n",
      "decays_line_plot.pdf\r\n",
      "\u001b[34mfilespace\u001b[m\u001b[m/\r\n",
      "\u001b[31mfilespace.zip\u001b[m\u001b[m*\r\n",
      "\u001b[34mfinal_project\u001b[m\u001b[m/\r\n",
      "\u001b[34mfinal_project_components\u001b[m\u001b[m/\r\n",
      "\u001b[34mkwfawkes.github.io\u001b[m\u001b[m/\r\n",
      "notebook-1.txt\r\n",
      "notebook-2.txt\r\n",
      "notes_day8.ipynb\r\n",
      "notes_day9.ipynb\r\n",
      "project.directory.sh\r\n",
      "\u001b[31msample_data_files.zip\u001b[m\u001b[m*\r\n",
      "somefile.txt\r\n",
      "\u001b[34mtext_book_data\u001b[m\u001b[m/\r\n",
      "worm_basal_locomotion.dat.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'sequence.fasta' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-14fc4cc5db45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#here I import the file as sequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sequence.fasta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    489\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3229)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6042)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'sequence.fasta' does not exist"
     ]
    }
   ],
   "source": [
    "#here I import the file as sequence.\n",
    "sequence = pd.read_csv('sequence.fasta', 'r',delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here I show that the sequence is viewable, by checking the first 10 lines\n",
    "sequence[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to count how many times the repeat happens in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "repeats = \"GTTGTGTTACCCTCGTAATTTTTGCTATCTAACAAC\"\n",
    "repeats = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (repeats.count('sequence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this prints a text file with the first line of the file, but not the rest.\n",
    "#if I run it again, it doubles the first line\n",
    "outfile = open('nospace.txt', 'a')\n",
    "for line in sequence:\n",
    "    \n",
    "        outfile.write(re.sub('\\n','',line))\n",
    "        \n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('nospace.txt') as text_file:\n",
    "    contents = text_file.read()\n",
    "print (contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#here I create a subset of the data, with 1 repeat, to show that the following count function\n",
    "#works.\n",
    "sequence_sub = \"TTTTTTAACCTTTTTTTATAAAATTACATTTATTAGTTTTACAAAGTTATCCACAGCGTTTTCGTGGATAGAATTGTGGGAAACTTTCCCACAAATTTCCCACATTGTGGAAAAGTGGGAAACTCTTTTGTTGGCTTTATAATGCATTTCTAATGCTCTTTTTGTCCACATTTTGGTGTTTTTCTAAATTGTTGCTAAAAAGTTATCCACAAATAATGTGGGAAACTTTTGAAACTTTTTCCACATTTATATGATATTCTATTATCACAACTAAAAGAACGGAGGTCTGTCATGAACATTTATGATGATTTGTGGAATAAGATTTTAAAAGATCTTGAGTACATCTATAGTGAAGAAGTTTATAATGAAATATTCGCTCCTATAAAGTCTACTCATAAATTCCAAAATGGTCTTATATTTGTTGTGTTACCCTCGTAATTTTTGCTATCTAACAACATAATTGTAGAATCTGAATTTATTAAAAACAGAATTTCAAGAATGTATATGCCTAAAATTAATGAACTCGCAACAAAACACTTTGATCAAGCAGTAAGATTTAAATTTGTAACTGCTCAAGACTTAATTAGTGAAGACTCACCAAAAGATAGAGTTCTGACAATTAACACCTACCGTCCTGGTAATTTAAATAATGCTTACTCGTTTGATAATTTCGTTGTTGGTAAGAGTAACACTTTCGCCTTTAGAATGGCTATGAAAGTAGCAGATCAACCAGGCGTAGTAGCTAACCCTTTCTATATTTTTGGGGATGTAGGTTTAGGTAAAACCCACTTAATGCAAGCAATCGG\"\n",
    "'sequence_sub = str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this shows that the re.search function does work, without the abbreviated names\n",
    "re.search('GTTGTGTTACCCTCGTAATTTTTGCTATCTAACAAC',\"TTTTTTAACCTTTTTTTATAAAATTACATTTATTAGTTTTACAAAGTTATCCACAGCGTTTTCGTGGATAGAATTGTGGGAAACTTTCCCACAAATTTCCCACATTGTGGAAAAGTGGGAAACTCTTTTGTTGGCTTTATAATGCATTTCTAATGCTCTTTTTGTCCACATTTTGGTGTTTTTCTAAATTGTTGCTAAAAAGTTATCCACAAATAATGTGGGAAACTTTTGAAACTTTTTCCACATTTATATGATATTCTATTATCACAACTAAAAGAACGGAGGTCTGTCATGAACATTTATGATGATTTGTGGAATAAGATTTTAAAAGATCTTGAGTACATCTATAGTGAAGAAGTTTATAATGAAATATTCGCTCCTATAAAGTCTACTCATAAATTCCAAAATGGTCTTATATTTGTTGTGTTACCCTCGTAATTTTTGCTATCTAACAACATAATTGTAGAATCTGAATTTATTAAAAACAGAATTTCAAGAATGTATATGCCTAAAATTAATGAACTCGCAACAAAACACTTTGATCAAGCAGTAAGATTTAAATTTGTAACTGCTCAAGACTTAATTAGTGAAGACTCACCAAAAGATAGAGTTCTGACAATTAACACCTACCGTCCTGGTAATTTAAATAATGCTTACTCGTTTGATAATTTCGTTGTTGGTAAGAGTAACACTTTCGCCTTTAGAATGGCTATGAAAGTAGCAGATCAACCAGGCGTAGTAGCTAACCCTTTCTATATTTTTGGGGATGTAGGTTTAGGTAAAACCCACTTAATGCAAGCAATCGG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here I attempt to use regular expression - search to look for repeats in sequence sub\n",
    "#not sure that I assigned sequence_sub and repeats as strings appropriately\n",
    "re.search('repeats', 'sequence_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#search Regular Expression - 1st pattern to find, second is what to look through\n",
    "#will show bar under cell if yes\n",
    "re.search('repeats', 'sequence_sub.count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"I cleaned up\" this data by finding out how many repeats are in my subset.  Next step is to figure out how to import a fasta file, and be able to edit it, use it as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here I import the file as plain text\n",
    "sequence = pd.read_csv('plain_text_genome.txt', 'r',delimiter='\\n')\n",
    "sequence.head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#here I show that the count function works to find a letter as a string, \n",
    "#and thus should work on a longer string like \n",
    "print (sequence_sub.count('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search('repeats','sequence_sub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if re.search('repeats'):\n",
    "        print (yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "handle = open(\"sequence.fasta\", \"rU\")\n",
    "for record in SeqIO.parse(handle, \"fasta\") :\n",
    "    print (record.id)\n",
    "handle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from Bio import SeqIO\n",
    " \n",
    "fasta_file = sequence\n",
    "def sequence_cleaner(fasta_file,min_length=0,por_n=100):\n",
    "    #create our hash table to add the sequences\n",
    "    sequences={}\n",
    " \n",
    "    #Using the biopython fasta parse we can read our fasta input\n",
    "    for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        #Take the current sequence\n",
    "        sequence=str(seq_record.seq).upper()\n",
    "        #Check if the current sequence is according to the user parameters\n",
    "        if (len(sequence)>=min_length and (float(sequence.count(\"N\"))/float(len(sequence)))*100<=por_n):\n",
    "       # If the sequence passed in the test \"is It clean?\" and It isnt in the hash table , the sequence and Its id are going to be in the hash\n",
    "            if sequence not in sequences:\n",
    "                sequences[sequence]=seq_record.id\n",
    "       #If It is already in the hash table, We're just gonna concatenate the ID of the current sequence to another one that is already in the hash table\n",
    "            else:\n",
    "                sequences[sequence]+=\"_\"+seq_record.id\n",
    " \n",
    " \n",
    "    #Write the clean sequences\n",
    " \n",
    "    #Create a file in the same directory where you ran this script\n",
    "    output_file=open(\"clear_\"+fasta_file,\"w+\")\n",
    "    #Just Read the Hash Table and write on the file as a fasta format\n",
    "    for sequence in sequences:\n",
    "            output_file.write(\">\"+sequences[sequence]+\"\\n\"+sequence+\"\\n\")\n",
    "    output_file.close()\n",
    " \n",
    "    print (CLEAN)\n",
    " \n",
    "userParameters=sys.argv[1:]\n",
    " \n",
    "try:\n",
    "    if len(userParameters)==1:\n",
    "        sequence_cleaner(userParameters[0])\n",
    "    elif len(userParameters)==2:\n",
    "        sequence_cleaner(userParameters[0],float(userParameters[1]))\n",
    "    elif len(userParameters)==3:\n",
    "        sequence_cleaner(userParameters[0],float(userParameters[1]),float(userParameters[2]))\n",
    "    else:\n",
    "        print ('problem')\n",
    "except:\n",
    "    print ('problem2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a biopython script for cleaning up fasta files.  Still not totally sure how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(genome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is not yet at the stage where the code can be evaluated for certain topics like efficiency and simplicity because of the major problems with loading biological sequence data. From what I observed, the necessary steps to solving the data loading problem are being taken. It appears as though three different methods for loading the data have been employed. My only comment on this topic is to keep trying different ways to load this data into python. While the data is not loaded in a format that can be analyzed, other strides have been made in the development of search and count code. Most of the cells have coments that explain the purpose and fucntion of each line of code, however more could have been included. I do realize that at this point much of the code written is just different ways of tackling the importing process, thus I am not sure if more comments and explanation are needed just yet. The 10 minute plan and or some the comments could have explained some of the jargon and background a little more. These explanations dont have to be much just a sentence or two more than the current 10 minute plan. The 10 minute plan is very effective at communicatiing the stage of development of the code, what needs to be done and where the developer wants to go next. This was very insightful. The At this stage of the assignment, I think all the final projects are in the development stage and thus cannot be fully evaluated for clarity or efficiency of code. The logical porcess here is great, and the developer just needs to keep emlpoying the same methods in order to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print my_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
